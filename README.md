# MyTSDB - High-Performance Time Series Database

**Version:** 1.0.0  
**Status:** Production-Ready Core, Active Development  
**Language:** C++17  
**License:** Apache 2.0

---

## ğŸ¯ Overview

MyTSDB is a high-performance, Prometheus-compatible time series database written in C++17. It features advanced optimizations including object pooling, multi-tier caching, predictive prefetching, and optional semantic vector capabilities for advanced analytics.

### Key Features

- âœ… **Prometheus-Compatible** - Label-based time series identification
- âœ… **PromQL Engine** - 100% complete (All functions, aggregation pushdown, 200+ tests, **O(1) Cache Lookup**)
- âœ… **Recording Rules (Derived Metrics)** - Pre-computed aggregations with error backoff, label filtering, staleness detection
- âœ… **Rate Limiting** - Configurable request throttling for API protection
- âœ… **Aggregation Pushdown** - ~785x speedup with storage-side computation
- âœ… **Write-Ahead Log (WAL)** - Crash recovery, durability, and **Safe Replay (Lock-free Init)**
- âœ… **Inverted Index** - Fast label-based queries
- âœ… **Multi-Tier Storage** - HOT/WARM/COLD tiers with automatic management
- âœ… **Object Pooling** - 99%+ object reuse for performance
- âœ… **Cache Hierarchy** - L1 (in-memory) + L3 (disk) caching
- âœ… **Compression** - Gorilla, Delta-of-Delta, XOR, RLE algorithms
- âœ… **Predictive Caching** - Pattern-based prefetching
- âœ… **Background Processing** - Async compaction and cleanup
- âœ… **Thread-Safe** - Lock-free data structures with Intel TBB
- âœ… **OpenTelemetry Support** - Native OTEL metric ingestion bridge
- âœ… **gRPC API** - High-performance query service
- âœ… **Prometheus Remote Storage** - Remote Write/Read API (18 tests passing)
- âœ… **Authentication** - Basic, Bearer, Header, Composite (25 tests passing)
- âœ… **Apache Parquet Storage** - Hybrid Hot/Cold architecture with ZSTD compression & Dictionary Encoding
- âš ï¸ **Semantic Vectors** - Optional advanced analytics (experimental)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Client API                             â”‚
â”‚  (C++ Library / gRPC Service / OTEL Bridge)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  StorageImpl (Core Storage Engine)                          â”‚
â”‚  â”œâ”€ Write-Ahead Log (WAL) - Durability                     â”‚
â”‚  â”œâ”€ Index (Inverted + Forward) - Fast Queries              â”‚
â”‚  â”œâ”€ Cache Hierarchy (L1/L3) - Performance                  â”‚
â”‚  â”œâ”€ Object Pools - Memory Efficiency                       â”‚
â”‚  â”œâ”€ Compression - Storage Efficiency                       â”‚
â”‚  â””â”€ Background Processor - Async Operations                â”‚
â”‚  â””â”€ Aggregation Pushdown - Query Optimization              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Block Manager (Multi-Tier Storage)                         â”‚
â”‚  â”œâ”€ HOT Tier: Recent data, no compression                  â”‚
â”‚  â”œâ”€ WARM Tier: Compressed, recent data                     â”‚
â”‚  â””â”€ COLD Tier: Highly compressed, archival                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

**Storage Layer:**
- `StorageImpl` - Main storage engine
- `WAL` - Write-ahead logging for crash recovery
- `Index` - Inverted index for label-based queries
- `BlockManager` - Multi-tier block storage

**Performance Layer:**
- `ObjectPool` - Memory-efficient object reuse (TimeSeriesPool, LabelsPool, SamplePool)
- `CacheHierarchy` - Multi-level caching (L1 active, L2 disabled)
- `PredictiveCache` - Pattern-based prefetching
- `BackgroundProcessor` - Async task execution
- `AggregationPushdown` - Storage-side aggregation execution (~785x speedup)
- `RateLimiter` - Request rate limiting for API protection

**Query & Recording Layer:**
- `PromQLEngine` - Full PromQL query parser and executor
- `DerivedMetricManager` - Recording rules with scheduling, backoff, and staleness
- `RuleGroup` - Sequential rule execution with shared intervals

**Integration Layer:**
- `OTELBridge` - OpenTelemetry metric conversion and ingestion
- `QueryService` - gRPC-based query interface
- `RemoteWriteHandler` - Prometheus Remote Write endpoint (`/api/v1/write`)
- `RemoteReadHandler` - Prometheus Remote Read endpoint (`/api/v1/read`)

**Compression Layer:**
- `GorillaCompressor` - Facebook's Gorilla algorithm for float values
- `DeltaOfDeltaEncoder` - Timestamp compression
- `XORCompressor` - XOR-based delta compression
- `RLECompressor` - Run-length encoding

---

## ğŸš€ Getting Started

**ğŸ‘‰ For detailed step-by-step instructions, see [GETTING_STARTED.md](GETTING_STARTED.md)**

### Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/mytsdb.git
cd mytsdb

# 2. Install dependencies (optional - auto-detects OS)
make deps

# 3. Build everything
make

# 4. Run all tests
make test-all
```

That's it! The project uses a Makefile wrapper around CMake for convenience. All operations can be done via Makefile targets.

### Prerequisites

- **Required:** C++17 compiler, CMake 3.15+, Make
- **Optional (but recommended):** Intel TBB, spdlog, Google Test, gRPC (required for OTEL support)

See [GETTING_STARTED.md](GETTING_STARTED.md) for detailed installation instructions for your platform.

### Quick Start

```cpp
#include "tsdb/storage/storage_impl.h"
#include "tsdb/core/types.h"

using namespace tsdb;

int main() {
    // Configure storage
    core::StorageConfig config = core::StorageConfig::Default();
    config.data_dir = "./tsdb_data";
    
    // Create storage instance
    storage::StorageImpl storage(config);
    
    // Initialize
    auto init_result = storage.init(config);
    if (!init_result.ok()) {
        std::cerr << "Init failed: " << init_result.error() << std::endl;
        return 1;
    }
    
    // Create time series
    core::Labels labels;
    labels.add("__name__", "cpu_usage");
    labels.add("host", "server1");
    core::TimeSeries series(labels);
    series.add_sample(std::time(nullptr) * 1000, 0.75);
    
    // Write
    auto write_result = storage.write(series);
    if (!write_result.ok()) {
        std::cerr << "Write failed: " << write_result.error() << std::endl;
        return 1;
    }
    
    // Read
    auto read_result = storage.read(labels, 0, std::time(nullptr) * 1000);
    if (read_result.ok()) {
        std::cout << "Read " << read_result.value().size() << " samples" << std::endl;
    }
    
    // Close
    storage.close();
    return 0;
}
```

---

## ğŸ“Š Performance

### Latest Benchmark Results (December 2024)

MyTSDB has achieved **enterprise-grade performance** through systematic optimization:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PERFORMANCE HIGHLIGHTS                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Write Throughput:    2,002,400 samples/sec (2M+)           â”‚
â”‚  Write P99 Latency:   65ms                                  â”‚
â”‚  Read P99 Latency:    56ms                                  â”‚
â”‚  Read Throughput:     550+ queries/sec                      â”‚
â”‚  Mutex Contention:    0.1% (down from 83%)                  â”‚
â”‚  Aggregations:        ~785x speedup (pushdown)              â”‚
â”‚  PromQL Cache:        O(1) lookup (1000x speedup)           â”‚
â”‚  Compression Ratio:   4-6x typical                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Evolution

| Phase | Read P99 | Write Throughput | Key Improvement |
|-------|----------|------------------|-----------------|
| Baseline | 1.8s | 226K/s | - |
| shared_mutex | 1.6s | 247K/s | Block-level concurrency |
| Zero-Copy Read | 1.0s | 500K/s | Vectorized data path |
| Parquet Opt | **50ms** | 1.7M/s | Time partitioning, batch demotion |
| **Concurrent Map** | **56ms** | **2M/s** | Lock-free series_blocks_ |

### Optimization Status

- âœ… **Lock-Free Write Path** - `tbb::concurrent_hash_map` for zero contention
- âœ… **Sharded WAL** - Per-series hash partitioning
- âœ… **Sharded Index** - Concurrent label lookups
- âœ… **Zero-Copy Reads** - Direct columnar access
- âœ… **Parquet Cold Storage** - ZSTD + Dictionary encoding
- âœ… **Object Pooling** - 99%+ object reuse
- âœ… **Aggregation Pushdown** - Storage-side computation

---

## ğŸ˜ Apache Parquet Storage Engine

MyTSDB features a state-of-the-art **Hybrid Storage Engine** that combines the speed of in-memory blocks with the efficiency of **Apache Parquet**.

### Key Capabilities
- **Hybrid Query Path**: Seamlessly queries data across Hot (Memory) and Cold (Parquet) tiers.
- **Columnar Efficiency**: Leverages Parquet's columnar layout for 10-50x better compression than row-based formats.
- **Advanced Encoding**:
  - **Dictionary Encoding**: For high-cardinality string labels.
  - **ZSTD Compression**: Tuned for optimal read/write balance.
- **Schema Evolution**: Supports changing dimensions (sparse columns) without exploding series cardinality.
- **Interoperability**: Data is stored in standard Parquet files, queryable by tools like **DuckDB**, **Pandas**, or **Spark**.

---

## â˜¸ï¸ Kubernetes Deployment

MyTSDB is designed for cloud-native deployment.

### Quick Deploy

```bash
# Deploy to current context
kubectl apply -f deployments/k8s/
```

### Architecture

- **StatefulSet**: Ensures stable network identity and persistent storage.
- **Headless Service**: Direct pod addressing for gRPC/OTEL.
- **PVC**: Persistent Volume Claims for data durability.

See [docs/deployment/KUBERNETES.md](docs/deployment/KUBERNETES.md) (TODO) for full guide.

---

## ğŸ”Œ Prometheus Remote Storage

MyTSDB implements the Prometheus Remote Storage API, allowing it to serve as a long-term storage backend for Prometheus and OTEL Collector.

### Quick Start

```bash
# Build and run the example server
make build

# Run without authentication
./build/examples/prometheus_remote_storage/prometheus_remote_storage_server 9090 none

# Run with Basic Auth
./build/examples/prometheus_remote_storage/prometheus_remote_storage_server 9090 basic

# Run with Bearer Token
./build/examples/prometheus_remote_storage/prometheus_remote_storage_server 9090 bearer
```

### Authentication

MyTSDB supports multiple authentication mechanisms:

- **No Auth** - Default, backward compatible
- **Basic Auth** - Username/password (HTTP Basic)
- **Bearer Token** - API tokens/JWT
- **Header-Based** - Multi-tenancy (X-Scope-OrgID)
- **Composite** - Multiple methods (AND/OR logic)

See **[AUTHENTICATION.md](AUTHENTICATION.md)** for complete guide with examples.

### Prometheus Configuration

Add to your `prometheus.yml`:

```yaml
remote_write:
  - url: "http://localhost:9090/api/v1/write"
    # Optional: Enable Snappy compression
    headers:
      Content-Encoding: snappy

remote_read:
  - url: "http://localhost:9090/api/v1/read"
    # Optional: Request Snappy compression
    headers:
      Accept-Encoding: snappy
```

### OTEL Collector Configuration

Add to your OTEL Collector config:

```yaml
exporters:
  prometheusremotewrite:
    endpoint: "http://localhost:9090/api/v1/write"
    # Optional: Add custom headers for multi-tenancy
    headers:
      X-Scope-OrgID: "tenant-1"

service:
  pipelines:
    metrics:
      receivers: [otlp]
      exporters: [prometheusremotewrite]
```

### Key Features

- **High Performance Storage**:
  - **Hot Tier**: In-memory, compressed blocks for recent data (write-optimized).
  - **Cold Tier**: **Apache Parquet** backed storage for historical data (read-optimized, high compression).
  - **Hybrid Query Engine**: Seamlessly queries across both memory and disk.
- **Advanced Compression**:
  - Gorilla/Delta-of-Delta for timestamps and values.
  - Dictionary Encoding and ZSTD for Parquet files.
- **Efficient Write Path**:
  - Optimized OTel-to-Internal conversion.
  - Background flushing and compaction.
- **Scalable Architecture**:
  - Designed for high cardinality (1M+ active series).
  - Multi-level caching (L1/L2).

### Features

- âœ… **Prometheus Remote Write** - Ingest metrics from Prometheus
- âœ… **Prometheus Remote Read** - Query historical data
- âœ… **Snappy Compression** - Optional compression for reduced bandwidth
- âœ… **Label Filtering** - Efficient label-based queries
- âœ… **Multi-tenancy Ready** - Custom header support
- âœ… **18 Tests Passing** - Comprehensive unit and integration tests

### Example Server

See [`examples/prometheus_remote_storage/`](examples/prometheus_remote_storage/) for a complete working example.

---

## ğŸ“š Documentation

### Getting Started

- **[GETTING_STARTED.md](GETTING_STARTED.md)** - Complete step-by-step setup guide â­ **START HERE**

### Core Documentation

- **[Architecture Overview](docs/architecture/ARCHITECTURE_OVERVIEW.md)** - System architecture
- **[Storage Architecture](docs/architecture/STORAGE_ARCHITECTURE.md)** - Storage system design
- **[Comprehensive Design Study](docs/planning/COMPREHENSIVE_DESIGN_STUDY.md)** - Complete codebase analysis
- **[API Documentation](docs/api/)** - API reference (TODO)

### Planning & Development

- **[Current Status](docs/planning/CURRENT_STATUS.md)** - Current project status
- **[Project State Analysis](docs/planning/PROJECT_STATE_ANALYSIS.md)** - Top-down project analysis
- **[Real Optimization Strategy](docs/planning/REAL_OPTIMIZATION_STRATEGY.md)** - Measurement-driven optimization
- **[Critical Lessons Learned](docs/planning/CRITICAL_LESSONS_LEARNED.md)** - Key learnings from development

### Testing

- **[StorageImpl Comprehensive Test Plan](docs/planning/STORAGEIMPL_COMPREHENSIVE_TEST_PLAN.md)** - Complete test strategy
- **[Integration Testing Plan](docs/planning/INTEGRATION_TESTING_PLAN.md)** - Integration test strategy
- **[Test README](test/README.md)** - Running tests
- **[OTEL/gRPC Tests](test/otel_grpc/README.md)** - OTEL integration tests

### Advanced Features

- **[PromQL & Recording Rules](docs/features/PROMQL_AND_RECORDING_RULES.md)** - Complete PromQL and derived metrics guide
- **[Aggregation Pushdown](docs/features/AGGREGATION_PUSHDOWN.md)** - Storage-side aggregation (~785x speedup)
- **[Rate Limiting](docs/features/RATE_LIMITING.md)** - API rate limiting configuration
- **[Semantic Vector Architecture](docs/architecture/SEMANTIC_VECTOR_ARCHITECTURE.md)** - Optional semantic vectors
- **[PromQL Engine](docs/planning/PROMQL_ENGINE_AGENT_TASKS.md)** - Query engine tasks
- **[LSM Implementation Plan](docs/planning/LSM_IMPLEMENTATION_PLAN.md)** - Future LSM storage

---

## ğŸ§ª Testing

### Running Tests

All tests are run via Makefile targets:

```bash
# Run all tests (600+ tests, ~7-8 minutes)
make test-all

# Unit tests only (357+ tests, ~2-3 minutes)
make test-unit

# Integration tests only (177+ tests, ~5-6 minutes)
make test-integration

# Specific test suites
make test-core-unit          # Core unit tests (38 tests)
make test-storage-unit       # Storage unit tests (60 tests)
make test-cache-unit         # Cache unit tests (28 tests)
make test-compression-unit   # Compression unit tests (19 tests)
make test-histogram-unit     # Histogram unit tests (22 tests)

# PromQL Comprehensive Tests (with data generation)
make test-promql-full        # Runs full PromQL suite (900+ tests)

# OTEL/gRPC Tests
make test-otel-grpc          # Runs all OTEL/gRPC tests

# Background test execution (for overnight runs)
make test-background-caffeinate  # macOS - prevents hibernation
make test-background-status      # Check status
make test-background-stop        # Stop tests
```

### Test Status

**Current Status:** 100% pass rate (600+ tests passing)

- âœ… **Unit Tests:** 350+ tests
- âœ… **Integration Tests:** 170+ tests
- âœ… **PromQL Tests:** 50+ comprehensive scenarios
- âœ… **OTEL/gRPC Tests:** Verified
- âœ… **Overall:** All passing

See [docs/planning/FAILING_TESTS_FIX_PLAN.md](docs/planning/FAILING_TESTS_FIX_PLAN.md) for detailed test status and results.

---

## ğŸ”§ Configuration

### Default Configuration

```cpp
Config config = Config::Default();
```

### Production Configuration

```cpp
Config config = Config::Production();
config.mutable_storage().cache_size_bytes = 4LL * 1024 * 1024 * 1024; // 4GB
config.mutable_query().max_concurrent_queries = 500;
```

### High-Performance Configuration

```cpp
Config config = Config::HighPerformance();
config.enable_semantic_vector(); // Enable advanced features
```

### Memory-Efficient Configuration

```cpp
Config config = Config::MemoryEfficient();
config.mutable_storage().cache_size_bytes = 512 * 1024 * 1024; // 512MB
```

### Key Configuration Options

```cpp
StorageConfig storage;
storage.data_dir = "./data";
storage.block_size = 64 * 1024 * 1024;           // 64MB blocks
storage.cache_size_bytes = 1024 * 1024 * 1024;   // 1GB cache
storage.enable_compression = true;

// Object pool configuration
storage.object_pool_config.time_series_max_size = 10000;
storage.object_pool_config.labels_max_size = 20000;
storage.object_pool_config.samples_max_size = 100000;

// Background processing (DISABLED by default for testing)
storage.background_config.enable_background_processing = false;
storage.background_config.enable_auto_compaction = false;
storage.background_config.enable_auto_cleanup = false;
```

---

## ğŸ› Known Issues

1. **L2 Cache Disabled** - Memory-mapped cache causes segfaults (under investigation)
2. **Background Processing Disabled** - Disabled by default for testing stability

---

## ğŸ—ºï¸ Roadmap

### Current Focus (v1.0)

- âœ… Core storage engine
- âœ… WAL and crash recovery
- âœ… Index and query support
- âœ… Compression and optimization
- âœ… Basic PromQL support (Phase 1)
- âœ… Performance optimization (Batching enabled)
- âš ï¸ Fix L2 cache (in progress)

### Next Release (v1.1)

- ğŸ”² Enable background processing
- ğŸ”² Fix L2 cache segfaults
- ğŸ”² Performance profiling and optimization
- ğŸ”² Enhanced PromQL support
- ğŸ”² Distributed sharding (for multi-machine deployment)

### Future (v2.0+)

- ğŸ”² LSM-tree storage option
- ğŸ”² Full semantic vector integration
- ğŸ”² Advanced query optimization
- ğŸ”² Kubernetes operator
- ğŸ”² Cloud-native features

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines (TODO) before submitting pull requests.

### Development Setup

```bash
# Install dependencies (auto-detects OS)
make deps

# Build with all features (tests enabled by default)
make

# Run all tests
make test-all

# Run specific test suite
make test-storage-unit

# Clean and rebuild
make clean-all && make rebuild
```

For more details, see [GETTING_STARTED.md](GETTING_STARTED.md).

---

## ğŸ“ License

Apache License 2.0 - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Prometheus** - Inspiration for label-based time series model
- **VictoriaMetrics** - Inspiration for multi-tier storage
- **Facebook Gorilla** - Compression algorithms
- **Intel TBB** - High-performance concurrency primitives
- **Google Test** - Testing framework

---

## ğŸ“§ Contact

- **Issues:** [GitHub Issues](https://github.com/yourusername/mytsdb/issues)
- **Discussions:** [GitHub Discussions](https://github.com/yourusername/mytsdb/discussions)
- **Email:** your.email@example.com

---

## ğŸ”— Related Projects

- [Prometheus](https://prometheus.io/) - Time series monitoring system
- [VictoriaMetrics](https://victoriametrics.com/) - Fast time series database
- [InfluxDB](https://www.influxdata.com/) - Time series platform
- [TimescaleDB](https://www.timescale.com/) - SQL time series database

---

**Built with â¤ï¸ for high-performance time series workloads**
